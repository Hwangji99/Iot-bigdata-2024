{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 객체탐지\n",
    "\n",
    "#### 개요\n",
    "- 딥러닝의 CNN(외 RCNN 등 여러 알고리즘)와 같은 알고리즘을 통해서 물체를 인식하여 표시하는 기술\n",
    "- 자동차번호판 번호 인식, 화재경보, 교통사고 인지, 이상행동 파악 등...\n",
    "- CCTV와 같이 접목해서 활용되는 경우가 아주 많음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 필요 라이브러리\n",
    "- OpenCV - 최초 인텔에서 개발한 오픈소스 실시간 컴퓨터 비전 라이브러리\n",
    "    - C/C++을 목표로 제작. 크로스 플랫폼\n",
    "    - 파이썬에 OpenCV가 적용되면서 활성화!\n",
    "    - 카메라 인식 산업에서 대부분 사용되고 있음\n",
    "    - C/C++에서 기본 동작코드 2~300줄이면 파이썬에선 10줄이내로 같은 작업을 할 수 있음\n",
    "\n",
    "- YOLO(PyTorch)\n",
    "    - Not You Only Live Once You Only Look Once!\n",
    "    - 손쉽게 사용할 수 있는 실시간 객체 탐지 시스템\n",
    "    - 2015년에 출시 후 현재 2024년 현재 V8.0\n",
    "    - OpenCV만 가지고 작업하던걸, YOLO로 넘어가는 추세"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Window, Mac 전혀 차이가 없음\n",
    "## Raspberry Pi는 최신버전에서 사용법이 변경되었음\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이미지 로드\n",
    "## 사막여우는 fennec_fox\n",
    "img = cv2.imread('./fennec_fox.png')\n",
    "\n",
    "cv2.imshow('Fox', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 현재 웹캠이 동작 안함\n",
    "video_path = './Mumbai_trafic.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "while True:\n",
    "    _, img = cap.read() # 실시간으로 화면을 캡쳐 ret(결과정보객체)은 보통 사용하지 않아서 _로 변경, img(실시간 이미지)\n",
    "    cv2.imshow('youtube mpeg', img) ## 내부적으로 PyQt로 생성되는 GUI창\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'): # 키보드 q를 클릭하면\n",
    "        break\n",
    "\n",
    "cap.release() # 자원 해제\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./fennec_fox.png')\n",
    "\n",
    "cv2.imshow('Original', img) ## 일반 이미지\n",
    "# cv2.waitKey(0) ## 일반 이미지\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "height, width = img.shape[0], img.shape[1]\n",
    "## 정수 입력 width/2 => float 문제\n",
    "half_img = cv2.resize(gray,(int(width/2), int(height/2)))\n",
    "# cv2.imshow('Gray', gray) ## 흑백으로 변환\n",
    "cv2.imshow('half', half_img)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = './Mumbai_trafic.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path) # 0 ~ 숫자는 카메라 번호\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "while True:\n",
    "    _, img = cap.read() # 실시간으로 화면을 캡쳐 ret(결과정보객체)은 보통 사용하지 않아서 _로 변경, img(실시간 이미지)\n",
    "    # cv2.imshow('youtube mpeg', img) ## 내부적으로 PyQt로 생성되는 GUI창\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) ## 컬러 -> 흑백으로\n",
    "    half = cv2.resize(gray,(int(width/2), int(height/2)))   ## 사이즈를 반으로 축소\n",
    "    cv2.imshow('youtube gray', half)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'): # 키보드 q를 클릭하면\n",
    "        break\n",
    "\n",
    "cap.release() # 자원 해제\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 포토샵 등의 이미지, 프리미어 등의 동영상 처리하는 프로그램에서 사용하는 거의 대부분의 기능이 OpenCV에 포함되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = './mbc_news.mp4'\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture(video_path) # 0 ~ 숫자는 카메라 번호\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read() # 실시간으로 화면을 캡쳐 ret(결과정보객체)은 보통 사용하지 않아서 _로 변경, img(실시간 이미지)\n",
    "    if not ret:\n",
    "        continue\n",
    "    \n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "\n",
    "    half = cv2.resize(img, (int(width/2), int(height/2)))\n",
    "\n",
    "    # 얼굴인식\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        half,\n",
    "        scaleFactor=1.2,\n",
    "        minNeighbors=5,\n",
    "        minSize=(10, 10)\n",
    "    )\n",
    "\n",
    "    # 찾은 얼굴 위치 표시\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(half,(x,y),(x+w,y+h),(0,255,255), 2)\n",
    "        roi_color = half[y:y+h, x:x+w]\n",
    "\n",
    "    cv2.imshow('youtube mpeg', half) ## 내부적으로 PyQt로 생성되는 GUI창\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'): # 키보드 q를 클릭하면\n",
    "        break\n",
    "\n",
    "cap.release() # 자원 해제\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pytube\n",
    "- 유튜브 컨텐츠, 메타데이터 검색 라이브러리\n",
    "\n",
    "- 완전 스트리밍 라이브러리 python-ffmpeg-video-streaming 등은 사용 비용 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pafy 설치\n",
    "!pip install pafy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install youtube_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pafy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downYoutube(videourl, path):\n",
    "    yt = YouTube(videourl)\n",
    "    yt = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
    "    if not os.path.exists(path): os.makedirs(path) ## 폴더가 없으면 생성\n",
    "\n",
    "    yt.download(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_url = 'https://www.youtube.com/watch?v=zxxfvP8-lrU'\n",
    "downYoutube(youtube_url, 'video')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### YOLO\n",
    "- You Only Look Once - CNN을 기반으로 한 물체 감지 라이브러리\n",
    "- https://www.ultralytics.com/ko\n",
    "- https://github.com/ultralytics/ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO 설치\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 콘솔창에서 테스트하는 방법, 트레이닝한 이미지처리 모델\n",
    "!yolo predict model=yolov8n.pt source='https://ultralytics.com/images/bus.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Sources\\Iot-bigdata-2024\\day07\\20240812_151755471.jpg: 384x640 1 bottle, 1 cup, 1 bowl, 1 tv, 1 mouse, 8.9ms\n",
      "Speed: 3.0ms preprocess, 8.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# 이미지와 openCV 물체감지\n",
    "model = YOLO(model='./yolov8n.pt')\n",
    "\n",
    "result = model('./20240812_151755471.jpg')\n",
    "plots = result[0].plot()\n",
    "height, width = plots.shape[0], plots.shape[1]\n",
    "last = cv2.resize(plots, (800, 450))\n",
    "cv2.imshow('yolo', last)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 실시간 가능, 동영상도 가능\n",
    "classNames = [\n",
    "                \"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "                \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "                \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "                \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "                \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "                \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "                \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "                \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "                \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "                \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = './Mumbai_trafic.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path) # 숫자는 CCTV,웹캠 등 실시간 영상\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    if ret == True:\n",
    "        height, width = img.shape[0], img.shape[1]\n",
    "        half = cv2.resize(img, (int(width/2), int(height/2)))\n",
    "        # YOLO로 물체검출 시작\n",
    "        results = model(half, stream=True)\n",
    "\n",
    "        ## 결과표시 like OpenCV 얼굴검출\n",
    "        for result in results:\n",
    "            ## 아래의 셀의 결과가 간단\n",
    "            boxes = result.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                cv2.rectangle(half, (x1,y1), (x2,y2), (0,255,255), 2) # 검출된 물체 박스그리기\n",
    "\n",
    "                ## 정확도 계산, Class name\n",
    "                accuracy = (box.conf[0]/100)*100\n",
    "                index = int(box.cls[0])\n",
    "                # print(f'Class name : {classNames[index]} / Accuracy : {accuracy:.2f}') # 콘솔프린트는 생략\n",
    "                title = f'{classNames[index]}, {accuracy:.2f}'\n",
    "                ## 박스위에 종류와 정확도출력\n",
    "                org = [x1, y1]\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                fontScale = 1\n",
    "                color = (0,255,255)\n",
    "                thickness = 2\n",
    "\n",
    "                cv2.putText(half, title, org, font, fontScale, color, thickness)\n",
    "\n",
    "        cv2.imshow('YOLOv8', half)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = './Mumbai_trafic.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path) # 숫자는 CCTV,웹캠 등 실시간 영상\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    if ret == True:\n",
    "        height, width = img.shape[0], img.shape[1]\n",
    "        half = cv2.resize(img, (int(width/2), int(height/2)))\n",
    "        results = model(half, stream=True)\n",
    "\n",
    "        for result in results:\n",
    "            last = result.plot()\n",
    "\n",
    "        cv2.imshow('YOLOv8', last)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = './Mumbai_trafic.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "out = cv2.VideoWriter('./Mumbai_traffic_result.mp4', fourcc=1446269005, fps=30, frameSize=(640, 360))\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    if ret == True:\n",
    "        height, width = img.shape[0], img.shape[1]\n",
    "        print(int(width/2), int(height/2))\n",
    "        half = cv2.resize(img, (int(width/2), int(height/2)))\n",
    "        results = model(half, stream=True)\n",
    "\n",
    "        for result in results:\n",
    "            last = result.plot()\n",
    "\n",
    "        cv2.imshow('YOLOv8', last)\n",
    "        out.write(last)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release() \n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
